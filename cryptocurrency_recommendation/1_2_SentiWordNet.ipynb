{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-2. SentiWordNet",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNn4dhaf2hFi"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdE_-DEP3SPq",
        "outputId": "b3597831-5855-46cd-ec06-8208b9312d80"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from pprint import pprint\n",
        "from datetime import datetime\n",
        "import collections\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "\n",
        "from wordcloud import WordCloud"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ucR3cAN3Wq6",
        "outputId": "16834f2c-f2cc-41b1-d663-18e6b6469d70"
      },
      "source": [
        "eng = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/3rd project/data/eng/tweets_labelled_09042020_16072020.csv', sep=';').set_index('id')\n",
        "eng.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x2DEMzjeab8",
        "outputId": "809018a6-f1da-48a8-ccb4-f5334fea6254"
      },
      "source": [
        "eng.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1300 entries, 77522 to 625070\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   created_at  1300 non-null   object\n",
            " 1   text        1300 non-null   object\n",
            " 2   sentiment   1300 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 40.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyq6pZ-Jtfvg"
      },
      "source": [
        "eng = eng[eng['sentiment'].notnull()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf7Awluy-DJ0"
      },
      "source": [
        "ticker_pattern = re.compile(r'(^\\$[A-Z]+|^\\$ES_F)')\n",
        "ht_pattern = re.compile(r'#\\w+')\n",
        "\n",
        "ticker_dic = collections.defaultdict(int)\n",
        "ht_dic = collections.defaultdict(int)\n",
        "\n",
        "for text in eng['text']:\n",
        "    for word in text.split():\n",
        "        if ticker_pattern.fullmatch(word) is not None:\n",
        "            ticker_dic[word[1:]] += 1\n",
        "\n",
        "            word = word.lower()\n",
        "            if ht_pattern.fullmatch(word) is not None:\n",
        "                ht_dic[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpH4vKfyH8MP"
      },
      "source": [
        "charonly = re.compile(r'[^a-zA-Z\\s]')\n",
        "handle_pattern = re.compile(r'@\\w+')\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                        u\"\\U00002702-\\U000027B0\"\n",
        "                        u\"\\U000024C2-\\U0001F251\"\n",
        "                        \"]+\", flags=re.UNICODE)\n",
        "url_pattern = re.compile(\n",
        "    'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "pic_pattern = re.compile('pic\\.twitter\\.com/.{10}')\n",
        "special_code = re.compile(r'(&amp;|&gt;|&lt;)')\n",
        "tag_pattern = re.compile(r'<.*?>')\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english')).union(\n",
        "    {'rt', 'retweet', 'RT', 'Retweet', 'RETWEET'})\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def hashtag(phrase):\n",
        "    return ht_pattern.sub(' ', phrase)\n",
        "\n",
        "def remove_ticker(phrase):\n",
        "    return ticker_pattern.sub('', phrase)\n",
        "    \n",
        "def specialcode(phrase):\n",
        "    return special_code.sub(' ', phrase)\n",
        "\n",
        "def emoji(phrase):\n",
        "    return emoji_pattern.sub(' ', phrase)\n",
        "\n",
        "def url(phrase):\n",
        "    return url_pattern.sub('', phrase)\n",
        "\n",
        "def pic(phrase):\n",
        "    return pic_pattern.sub('', phrase)\n",
        "\n",
        "def html_tag(phrase):\n",
        "    return tag_pattern.sub(' ', phrase)\n",
        "\n",
        "def handle(phrase):\n",
        "    return handle_pattern.sub('', phrase)\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    \n",
        "    # DIS, ticker symbol of Disney, is interpreted as the plural of \"DI\" \n",
        "    # in WordCloud, so I converted it to Disney\n",
        "    phrase = re.sub('DIS', 'Disney', phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"(he|He)\\'s\", \"he is\", phrase)\n",
        "    phrase = re.sub(r\"(she|She)\\'s\", \"she is\", phrase)\n",
        "    phrase = re.sub(r\"(it|It)\\'s\", \"it is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"(\\'ve|has)\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase\n",
        "\n",
        "def onlychar(phrase):\n",
        "    return charonly.sub('', phrase)\n",
        "\n",
        "def remove_stopwords(phrase):\n",
        "    return \" \".join([word for word in str(phrase).split()\\\n",
        "                     if word not in STOPWORDS])\n",
        "\n",
        "def tokenize_stem(phrase):   \n",
        "    tokens = word_tokenize(phrase)\n",
        "    stem_words =[]\n",
        "    for token in tokens:\n",
        "        word = lemmatizer.lemmatize(token)\n",
        "        stem_words.append(word)        \n",
        "    buf = ' '.join(stem_words)    \n",
        "    return buf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wARDi25oYR0E"
      },
      "source": [
        "def arrange_text(ds):\n",
        "    ds['text2'] = ds['text'].apply(emoji)\n",
        "    ds['text2'] = ds['text2'].apply(handle)\n",
        "    ds['text2'] = ds['text2'].apply(specialcode)\n",
        "    ds['text2'] = ds['text2'].apply(hashtag)\n",
        "    ds['text2'] = ds['text2'].apply(url)\n",
        "    ds['text2'] = ds['text2'].apply(pic)\n",
        "    ds['text2'] = ds['text2'].apply(html_tag)\n",
        "    ds['text2'] = ds['text2'].apply(onlychar)\n",
        "    ds['text2'] = ds['text2'].apply(decontracted)\n",
        "    ds['text2'] = ds['text2'].apply(onlychar)\n",
        "    ds['text2'] = ds['text2'].apply(tokenize_stem)\n",
        "    ds['text2'] = ds['text2'].apply(remove_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABiZYts2YVqf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "1c374f75-fe6d-4d4f-cbbe-7d151a16724e"
      },
      "source": [
        "arrange_text(eng)\n",
        "eng.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77522</th>\n",
              "      <td>2020-04-15 01:03:46+00:00</td>\n",
              "      <td>RT @RobertBeadles: Yo💥\\nEnter to WIN 1,000 Mon...</td>\n",
              "      <td>positive</td>\n",
              "      <td>Yo Enter WIN Monarch Tokens US Stock Market Cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661634</th>\n",
              "      <td>2020-06-25 06:20:06+00:00</td>\n",
              "      <td>#SriLanka surcharge on fuel removed!\\n⛽📉\\nThe ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>surcharge fuel removed The surcharge Rs impose...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413231</th>\n",
              "      <td>2020-06-04 15:41:45+00:00</td>\n",
              "      <td>Net issuance increases to fund fiscal programs...</td>\n",
              "      <td>positive</td>\n",
              "      <td>Net issuance increase fund fiscal program yiel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760262</th>\n",
              "      <td>2020-07-03 19:39:35+00:00</td>\n",
              "      <td>RT @bentboolean: How much of Amazon's traffic ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>How much Amazons traffic served Fastly Help u ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830153</th>\n",
              "      <td>2020-07-09 14:39:14+00:00</td>\n",
              "      <td>$AMD Ryzen 4000 desktop CPUs looking ‘great’ a...</td>\n",
              "      <td>positive</td>\n",
              "      <td>AMD Ryzen desktop CPUs looking great track launch</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       created_at  ...                                              text2\n",
              "id                                 ...                                                   \n",
              "77522   2020-04-15 01:03:46+00:00  ...  Yo Enter WIN Monarch Tokens US Stock Market Cr...\n",
              "661634  2020-06-25 06:20:06+00:00  ...  surcharge fuel removed The surcharge Rs impose...\n",
              "413231  2020-06-04 15:41:45+00:00  ...  Net issuance increase fund fiscal program yiel...\n",
              "760262  2020-07-03 19:39:35+00:00  ...  How much Amazons traffic served Fastly Help u ...\n",
              "830153  2020-07-09 14:39:14+00:00  ...  AMD Ryzen desktop CPUs looking great track launch\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "Qx8aGvhJAueE",
        "outputId": "9f2350de-7a56-4c37-8c99-a5b278234a8a"
      },
      "source": [
        "eng = eng.replace({'sentiment': 'positive'}, {'sentiment': 0})\n",
        "eng = eng.replace({'sentiment': 'neutral'}, {'sentiment': 1})\n",
        "eng = eng.replace({'sentiment': 'negative'}, {'sentiment': 2})\n",
        "\n",
        "eng.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77522</th>\n",
              "      <td>2020-04-15 01:03:46+00:00</td>\n",
              "      <td>RT @RobertBeadles: Yo💥\\nEnter to WIN 1,000 Mon...</td>\n",
              "      <td>0</td>\n",
              "      <td>Yo Enter WIN Monarch Tokens US Stock Market Cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661634</th>\n",
              "      <td>2020-06-25 06:20:06+00:00</td>\n",
              "      <td>#SriLanka surcharge on fuel removed!\\n⛽📉\\nThe ...</td>\n",
              "      <td>2</td>\n",
              "      <td>surcharge fuel removed The surcharge Rs impose...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413231</th>\n",
              "      <td>2020-06-04 15:41:45+00:00</td>\n",
              "      <td>Net issuance increases to fund fiscal programs...</td>\n",
              "      <td>0</td>\n",
              "      <td>Net issuance increase fund fiscal program yiel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760262</th>\n",
              "      <td>2020-07-03 19:39:35+00:00</td>\n",
              "      <td>RT @bentboolean: How much of Amazon's traffic ...</td>\n",
              "      <td>0</td>\n",
              "      <td>How much Amazons traffic served Fastly Help u ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830153</th>\n",
              "      <td>2020-07-09 14:39:14+00:00</td>\n",
              "      <td>$AMD Ryzen 4000 desktop CPUs looking ‘great’ a...</td>\n",
              "      <td>0</td>\n",
              "      <td>AMD Ryzen desktop CPUs looking great track launch</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       created_at  ...                                              text2\n",
              "id                                 ...                                                   \n",
              "77522   2020-04-15 01:03:46+00:00  ...  Yo Enter WIN Monarch Tokens US Stock Market Cr...\n",
              "661634  2020-06-25 06:20:06+00:00  ...  surcharge fuel removed The surcharge Rs impose...\n",
              "413231  2020-06-04 15:41:45+00:00  ...  Net issuance increase fund fiscal program yiel...\n",
              "760262  2020-07-03 19:39:35+00:00  ...  How much Amazons traffic served Fastly Help u ...\n",
              "830153  2020-07-09 14:39:14+00:00  ...  AMD Ryzen desktop CPUs looking great track launch\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "HXr9Wc-yilwO",
        "outputId": "0d6aace2-4424-4424-d82e-c576024f2c26"
      },
      "source": [
        "eng['dic_s'] = \"\"\n",
        "eng.head()f"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text2</th>\n",
              "      <th>dic_s</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77522</th>\n",
              "      <td>2020-04-15 01:03:46+00:00</td>\n",
              "      <td>RT @RobertBeadles: Yo💥\\nEnter to WIN 1,000 Mon...</td>\n",
              "      <td>0</td>\n",
              "      <td>Yo Enter WIN Monarch Tokens US Stock Market Cr...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661634</th>\n",
              "      <td>2020-06-25 06:20:06+00:00</td>\n",
              "      <td>#SriLanka surcharge on fuel removed!\\n⛽📉\\nThe ...</td>\n",
              "      <td>2</td>\n",
              "      <td>surcharge fuel removed The surcharge Rs impose...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413231</th>\n",
              "      <td>2020-06-04 15:41:45+00:00</td>\n",
              "      <td>Net issuance increases to fund fiscal programs...</td>\n",
              "      <td>0</td>\n",
              "      <td>Net issuance increase fund fiscal program yiel...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760262</th>\n",
              "      <td>2020-07-03 19:39:35+00:00</td>\n",
              "      <td>RT @bentboolean: How much of Amazon's traffic ...</td>\n",
              "      <td>0</td>\n",
              "      <td>How much Amazons traffic served Fastly Help u ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830153</th>\n",
              "      <td>2020-07-09 14:39:14+00:00</td>\n",
              "      <td>$AMD Ryzen 4000 desktop CPUs looking ‘great’ a...</td>\n",
              "      <td>0</td>\n",
              "      <td>AMD Ryzen desktop CPUs looking great track launch</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       created_at  ... dic_s\n",
              "id                                 ...      \n",
              "77522   2020-04-15 01:03:46+00:00  ...      \n",
              "661634  2020-06-25 06:20:06+00:00  ...      \n",
              "413231  2020-06-04 15:41:45+00:00  ...      \n",
              "760262  2020-07-03 19:39:35+00:00  ...      \n",
              "830153  2020-07-09 14:39:14+00:00  ...      \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbdnbYBDVSJb"
      },
      "source": [
        "* https://statkclee.github.io/nlp2/nlp-sentiment.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZhS91uxeOeA"
      },
      "source": [
        "def penn_to_wn(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    elif tag.startswith('Y'):\n",
        "        return wn.VERB\n",
        "    return None\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.replace('<br />', \"\")\n",
        "    return text\n",
        "\n",
        "def swn_polarity(text):\n",
        "    sentiment = 0.0\n",
        "    tokens_count = 0\n",
        "\n",
        "    text = clean_text(text)\n",
        "\n",
        "    raw_sentences = sent_tokenize(text)\n",
        "    for raw_sentence in raw_sentences:\n",
        "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
        "\n",
        "        for word, tag in tagged_sentence:\n",
        "            wn_tag = penn_to_wn(tag)\n",
        "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
        "                continue\n",
        "\n",
        "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "\n",
        "            if not lemma:\n",
        "                continue\n",
        "\n",
        "            synsets = wn.synsets(lemma, pos = wn_tag)\n",
        "            if not synsets:\n",
        "                continue\n",
        "\n",
        "            synset = synsets[0]\n",
        "            swn_synset = swn.senti_synset(synset.name())\n",
        "\n",
        "            sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
        "            tokens_count += 1\n",
        "\n",
        "    if not tokens_count:\n",
        "        return 1\n",
        "\n",
        "    if sentiment > 0:\n",
        "        return 0\n",
        "\n",
        "    elif sentiment == 0:\n",
        "        return 1\n",
        "\n",
        "    return 2\n",
        "\n",
        "for index, row in eng.loc[:, :].iterrows():\n",
        "    text = row['text2']\n",
        "#    print(f'Text {index} : {text.strip()}')\n",
        " #   print('Sentiment :', row['sentiment'])\n",
        "  #  print('Predicted Sentiment polarity : ', swn_polarity(text))\n",
        "   # print('-'*60)\n",
        "    eng['dic_s'][index] = swn_polarity(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq1SUyaqmm_i",
        "outputId": "31379004-b783-4ddb-ddde-3b76a5960e44"
      },
      "source": [
        "eng['dic_s'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    539\n",
              "1    442\n",
              "2    319\n",
              "Name: dic_s, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "-e4GNPaQlj8v",
        "outputId": "b6359f31-a920-4b20-937d-17726ad3594d"
      },
      "source": [
        "eng.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text2</th>\n",
              "      <th>dic_s</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77522</th>\n",
              "      <td>2020-04-15 01:03:46+00:00</td>\n",
              "      <td>RT @RobertBeadles: Yo💥\\nEnter to WIN 1,000 Mon...</td>\n",
              "      <td>0</td>\n",
              "      <td>Yo Enter WIN Monarch Tokens US Stock Market Cr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661634</th>\n",
              "      <td>2020-06-25 06:20:06+00:00</td>\n",
              "      <td>#SriLanka surcharge on fuel removed!\\n⛽📉\\nThe ...</td>\n",
              "      <td>2</td>\n",
              "      <td>surcharge fuel removed The surcharge Rs impose...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413231</th>\n",
              "      <td>2020-06-04 15:41:45+00:00</td>\n",
              "      <td>Net issuance increases to fund fiscal programs...</td>\n",
              "      <td>0</td>\n",
              "      <td>Net issuance increase fund fiscal program yiel...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760262</th>\n",
              "      <td>2020-07-03 19:39:35+00:00</td>\n",
              "      <td>RT @bentboolean: How much of Amazon's traffic ...</td>\n",
              "      <td>0</td>\n",
              "      <td>How much Amazons traffic served Fastly Help u ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830153</th>\n",
              "      <td>2020-07-09 14:39:14+00:00</td>\n",
              "      <td>$AMD Ryzen 4000 desktop CPUs looking ‘great’ a...</td>\n",
              "      <td>0</td>\n",
              "      <td>AMD Ryzen desktop CPUs looking great track launch</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27027</th>\n",
              "      <td>2020-04-12 21:52:56+00:00</td>\n",
              "      <td>RT @QuantTrend: Reduce your portfolio RISK! GO...</td>\n",
              "      <td>0</td>\n",
              "      <td>Reduce portfolio RISK GOLD perfect tail HEDGE ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472959</th>\n",
              "      <td>2020-06-09 05:23:06+00:00</td>\n",
              "      <td>$863.69 Million in Sales Expected for Spirit A...</td>\n",
              "      <td>0</td>\n",
              "      <td>Million Sales Expected Spirit AeroSystems Hold...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392845</th>\n",
              "      <td>2020-06-02 01:12:29+00:00</td>\n",
              "      <td>RT @ArjunKharpal: #Apple has cut the prices of...</td>\n",
              "      <td>2</td>\n",
              "      <td>cut price iPhone range China Its uncommon move...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313771</th>\n",
              "      <td>2020-05-07 04:58:41+00:00</td>\n",
              "      <td>RT @SMA_alpha: The #CDC U.S. New Case data has...</td>\n",
              "      <td>2</td>\n",
              "      <td>The US New Case data day lag saw another encou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267894</th>\n",
              "      <td>2020-05-04 15:16:29+00:00</td>\n",
              "      <td>Where to Look for Dependable Dividends\\nRead M...</td>\n",
              "      <td>1</td>\n",
              "      <td>Where Look Dependable Dividends Read More</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223041</th>\n",
              "      <td>2020-04-27 00:41:06+00:00</td>\n",
              "      <td>RT @PipsToDollars: Earnings $AMZN $TSLA $MSFT ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Earnings AMZN TSLA MSFT AAPL AMD BA FB LUV MMM...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417260</th>\n",
              "      <td>2020-06-04 07:29:51+00:00</td>\n",
              "      <td>Guys if market stays below 10000 till 2 expect...</td>\n",
              "      <td>2</td>\n",
              "      <td>Guys market stay till expect major major crash...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436313</th>\n",
              "      <td>2020-06-06 15:06:34+00:00</td>\n",
              "      <td>How will the future fly for Spirit Air $SAVE ?...</td>\n",
              "      <td>1</td>\n",
              "      <td>How future fly Spirit Air SAVE Stocks Sports F...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516487</th>\n",
              "      <td>2020-06-14 18:33:57+00:00</td>\n",
              "      <td>Interesting comparison to 2007-09 market of $S...</td>\n",
              "      <td>2</td>\n",
              "      <td>Interesting comparison market SPX stock day Mu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378564</th>\n",
              "      <td>2020-06-01 09:27:28+00:00</td>\n",
              "      <td>#CANBK\\n\\nCANBK 25-Jun-2020 , Now @ 93++++++++...</td>\n",
              "      <td>1</td>\n",
              "      <td>CANBK Jun Now</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539347</th>\n",
              "      <td>2020-06-16 17:36:40+00:00</td>\n",
              "      <td>4/ that is, Spot premium. No major price peaks...</td>\n",
              "      <td>0</td>\n",
              "      <td>Spot premium No major price peak p havee Durin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>739221</th>\n",
              "      <td>2020-07-01 11:30:04+00:00</td>\n",
              "      <td>Chile: On The Road to Recovery in 2021? https:...</td>\n",
              "      <td>1</td>\n",
              "      <td>Chile On The Road Recovery AAPL TSLA FB</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310725</th>\n",
              "      <td>2020-05-07 13:10:28+00:00</td>\n",
              "      <td>RT @ForecastCity: Latest #EURNZD #TradeIdeas &amp;...</td>\n",
              "      <td>0</td>\n",
              "      <td>Latest FREE pip day</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>836967</th>\n",
              "      <td>2020-07-09 02:30:51+00:00</td>\n",
              "      <td>$VIR \\n\\nSince April i posted these levels \\n\\...</td>\n",
              "      <td>0</td>\n",
              "      <td>VIR Since April posted level Just follow threa...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67928</th>\n",
              "      <td>2020-04-15 16:46:49+00:00</td>\n",
              "      <td>@EpiphronR  China Population 1.3 Billion Reaso...</td>\n",
              "      <td>1</td>\n",
              "      <td>China Population Billion Reasons IQ IQIYI GLUU...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       created_at  ... dic_s\n",
              "id                                 ...      \n",
              "77522   2020-04-15 01:03:46+00:00  ...     0\n",
              "661634  2020-06-25 06:20:06+00:00  ...     1\n",
              "413231  2020-06-04 15:41:45+00:00  ...     2\n",
              "760262  2020-07-03 19:39:35+00:00  ...     0\n",
              "830153  2020-07-09 14:39:14+00:00  ...     0\n",
              "27027   2020-04-12 21:52:56+00:00  ...     0\n",
              "472959  2020-06-09 05:23:06+00:00  ...     1\n",
              "392845  2020-06-02 01:12:29+00:00  ...     0\n",
              "313771  2020-05-07 04:58:41+00:00  ...     0\n",
              "267894  2020-05-04 15:16:29+00:00  ...     0\n",
              "223041  2020-04-27 00:41:06+00:00  ...     0\n",
              "417260  2020-06-04 07:29:51+00:00  ...     0\n",
              "436313  2020-06-06 15:06:34+00:00  ...     2\n",
              "516487  2020-06-14 18:33:57+00:00  ...     2\n",
              "378564  2020-06-01 09:27:28+00:00  ...     1\n",
              "539347  2020-06-16 17:36:40+00:00  ...     0\n",
              "739221  2020-07-01 11:30:04+00:00  ...     1\n",
              "310725  2020-05-07 13:10:28+00:00  ...     0\n",
              "836967  2020-07-09 02:30:51+00:00  ...     2\n",
              "67928   2020-04-15 16:46:49+00:00  ...     2\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spy0iqiwmdWz",
        "outputId": "f8fe4767-0b2a-4ee8-cfb8-ffcbaa4a6fb9"
      },
      "source": [
        "true = 0\n",
        "\n",
        "for index, row in eng.loc[:, :].iterrows():\n",
        "    if eng['sentiment'][index] == eng['dic_s'][index]:\n",
        "        true += 1\n",
        "\n",
        "print(true)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ar9iexyuLSY",
        "outputId": "17d399de-f410-4425-cc22-ff73c376d4b1"
      },
      "source": [
        "print('accuracy = ', 641/1300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy =  0.4930769230769231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spkv8On2uUO7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}